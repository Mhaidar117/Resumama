{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumama\n",
    "Resumama leverages a fine-tuned T5-small transformer model to analyze job postings and generate one-page, tailored resumes optimized for each application. By predicting the fit between a candidate's long-format resume and a given job post, Resumama provides a three-tiered recommendation: \"Good Fit,\" \"Potential Fit,\" or \"No Fit.\" For suitable matches, the system then generates a concise, professional resume highlighting the most relevant qualifications and experiences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 11.8\n",
      "Device Name: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5-Small\n",
    "T5-small is a compact version of the Text-to-Text Transfer Transformer (T5) model, developed by Google. It treats every NLP task as a text-to-text problem, enabling it to perform tasks such as translation, summarization, and classification within a unified framework. With 60 million parameters, T5-small balances computational efficiency and performance, making it suitable for resource-constrained applications while maintaining robust language understanding capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model = model.to(\"cpu\")\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "The data used for training contains pairs of resume texts and job descriptions, annotated with labels indicating the fit level (\"Good Fit,\" \"Potential Fit,\" or \"No Fit\"). It includes a total of 4,992 samples, with the majority labeled as \"No Fit\" (3,143), followed by \"Potential Fit\" (1,556), and \"Good Fit\" (1,542). Each record consists of a candidate's resume, a corresponding job description, and a fit label, allowing the model to learn the relationship between resumes and job requirements. The class imbalance in the dataset, with more \"No Fit\" examples, may present challenges for training, potentially requiring rebalancing techniques or weighting adjustments to improve classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "df = pd.read_csv(\"hf://datasets/cnamuangtoun/resume-job-description-fit/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Fit           3143\n",
       "Potential Fit    1556\n",
       "Good Fit         1542\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "'''\n",
    "preprocess_data takes in a dataframe and a tokenizer and returns a dictionary of inputs and outputs that are ready to be passed to the model\n",
    "'''\n",
    "# Prepare the data\n",
    "def preprocess_data(df, tokenizer, max_length=512):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        input_text = (f\"Evaluate the fit level of the following resume for the job description. Understand what makes a resume a good fit.\"\n",
    "                      f\"Job Description: {row['job_description_text']} \"\n",
    "                      f\"Resume: {row['resume_text']}\")\n",
    "        label_text = row['label']\n",
    "        \n",
    "        inputs.append(input_text)\n",
    "        labels.append(label_text)\n",
    "\n",
    "    # Tokenize the inputs and outputs\n",
    "    tokenized_inputs = tokenizer(inputs, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    tokenized_labels = tokenizer(labels, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Return tokenized inputs and labels\n",
    "    return tokenized_inputs, tokenized_labels\n",
    "\n",
    "# Split data into train and validation\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "train_inputs, train_labels = preprocess_data(train_df, tokenizer)\n",
    "val_inputs, val_labels = preprocess_data(val_df, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_text</th>\n",
       "      <th>job_description_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>SummaryA business management graduate with sig...</td>\n",
       "      <td>Position Title: Senior Accountant Organization...</td>\n",
       "      <td>Potential Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>Professional ProfileCapable International Tax ...</td>\n",
       "      <td>RoleGaming Business AnalystResponsibilities Ab...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Professional ProfileHighly motivated Sales Ass...</td>\n",
       "      <td>If you can handle the accounting responsibilit...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>SummaryOrganized and motivated employee eager ...</td>\n",
       "      <td>Our client is a growing Medical Device company...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>SummaryEmployed by the U.S. Navy as a Civilian...</td>\n",
       "      <td>Were seeking a detail-oriented and analytical ...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>Professional ProfileExpert in Functional Testi...</td>\n",
       "      <td>Lead Software Developer  New York City - Hybr...</td>\n",
       "      <td>Potential Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>SummaryI am a detail-oriented professional see...</td>\n",
       "      <td>Job Purpose: Perform designated tasks in the a...</td>\n",
       "      <td>Good Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>SummaryDedicated and focused Clerk who excels ...</td>\n",
       "      <td>Role - Business Analyst - Mobile Location - Lo...</td>\n",
       "      <td>Good Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>SummaryTo obtain a challenging and rewarding a...</td>\n",
       "      <td>About Allvue\\nWe are Allvue Systems, the leadi...</td>\n",
       "      <td>Good Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Career FocusAccomplished and results oriented ...</td>\n",
       "      <td>Skills QualificationsBachelors degree in Accou...</td>\n",
       "      <td>No Fit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            resume_text  \\\n",
       "3659  SummaryA business management graduate with sig...   \n",
       "1426  Professional ProfileCapable International Tax ...   \n",
       "497   Professional ProfileHighly motivated Sales Ass...   \n",
       "2833  SummaryOrganized and motivated employee eager ...   \n",
       "1480  SummaryEmployed by the U.S. Navy as a Civilian...   \n",
       "...                                                 ...   \n",
       "3772  Professional ProfileExpert in Functional Testi...   \n",
       "5191  SummaryI am a detail-oriented professional see...   \n",
       "5226  SummaryDedicated and focused Clerk who excels ...   \n",
       "5390  SummaryTo obtain a challenging and rewarding a...   \n",
       "860   Career FocusAccomplished and results oriented ...   \n",
       "\n",
       "                                   job_description_text          label  \n",
       "3659  Position Title: Senior Accountant Organization...  Potential Fit  \n",
       "1426  RoleGaming Business AnalystResponsibilities Ab...         No Fit  \n",
       "497   If you can handle the accounting responsibilit...         No Fit  \n",
       "2833  Our client is a growing Medical Device company...         No Fit  \n",
       "1480  Were seeking a detail-oriented and analytical ...         No Fit  \n",
       "...                                                 ...            ...  \n",
       "3772   Lead Software Developer  New York City - Hybr...  Potential Fit  \n",
       "5191  Job Purpose: Perform designated tasks in the a...       Good Fit  \n",
       "5226  Role - Business Analyst - Mobile Location - Lo...       Good Fit  \n",
       "5390  About Allvue\\nWe are Allvue Systems, the leadi...       Good Fit  \n",
       "860   Skills QualificationsBachelors degree in Accou...         No Fit  \n",
       "\n",
       "[4992 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "''' \n",
    "fit_level_dataset is a custom dataset class that takes in tokenized inputs and labels and returns a dictionary of input_ids, attention_mask, and labels\n",
    "'''\n",
    "class FitLevelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings.input_ids[idx],\n",
    "            \"attention_mask\": self.encodings.attention_mask[idx],\n",
    "            \"labels\": self.labels.input_ids[idx],\n",
    "        }\n",
    "\n",
    "train_dataset = FitLevelDataset(train_inputs, train_labels)\n",
    "val_dataset = FitLevelDataset(val_inputs, val_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune\n",
    "Here we fine-tune a pre-trained T5-small model on our resume dataset. The T5ForConditionalGeneration class is used to load the pre-trained model, which is capable of generating text conditioned on input text. Training arguments are configured via TrainingArguments, specifying parameters like the output directory, evaluation strategy, batch size, number of epochs, learning rate, and precision mode. The Trainer class orchestrates the training process, combining the model, training arguments, and datasets (training and validation). Finally, the trainer.train() call initiates the fine-tuning process, updating the model weights based on the input data to optimize its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562eed1954f64ba4addda9aa8ce93ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.79, 'grad_norm': 2.7435436248779297, 'learning_rate': 2.9703725961538463e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d0d2ad5783481f9493dc787733e87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6606224179267883, 'eval_runtime': 22.0997, 'eval_samples_per_second': 56.517, 'eval_steps_per_second': 56.517, 'epoch': 0.1}\n",
      "{'loss': 0.5865, 'grad_norm': 7.690234661102295, 'learning_rate': 2.9403245192307694e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c90f9f637443e1b98b59481fe767d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4432353377342224, 'eval_runtime': 21.9501, 'eval_samples_per_second': 56.902, 'eval_steps_per_second': 56.902, 'epoch': 0.2}\n",
      "{'loss': 0.5665, 'grad_norm': 0.49165016412734985, 'learning_rate': 2.9102764423076925e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6c4e98baa543f68f50f9afa452e0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5360539555549622, 'eval_runtime': 22.294, 'eval_samples_per_second': 56.024, 'eval_steps_per_second': 56.024, 'epoch': 0.3}\n",
      "{'loss': 0.5685, 'grad_norm': 14.284967422485352, 'learning_rate': 2.8802283653846156e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4953f67dfb374c18a4f49fece9222f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6435320973396301, 'eval_runtime': 21.9825, 'eval_samples_per_second': 56.818, 'eval_steps_per_second': 56.818, 'epoch': 0.4}\n",
      "{'loss': 0.5467, 'grad_norm': 1.1861993074417114, 'learning_rate': 2.8501802884615383e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee7d1b9caad4168b1cfeef69f914f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4955109655857086, 'eval_runtime': 22.2931, 'eval_samples_per_second': 56.026, 'eval_steps_per_second': 56.026, 'epoch': 0.5}\n",
      "{'loss': 0.5284, 'grad_norm': 0.9705380797386169, 'learning_rate': 2.8201322115384614e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fedf5e478a341ae91f68e47b726181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4090416431427002, 'eval_runtime': 21.988, 'eval_samples_per_second': 56.804, 'eval_steps_per_second': 56.804, 'epoch': 0.6}\n",
      "{'loss': 0.5065, 'grad_norm': 3.2549123764038086, 'learning_rate': 2.790084134615385e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7c9a1ddfe3488ca7c71359a5d44332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3828349709510803, 'eval_runtime': 21.743, 'eval_samples_per_second': 57.444, 'eval_steps_per_second': 57.444, 'epoch': 0.7}\n",
      "{'loss': 0.5345, 'grad_norm': 7.248378753662109, 'learning_rate': 2.760036057692308e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620c3de580b448cabd3fe57fa1b8d858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33548596501350403, 'eval_runtime': 21.9477, 'eval_samples_per_second': 56.908, 'eval_steps_per_second': 56.908, 'epoch': 0.8}\n",
      "{'loss': 0.485, 'grad_norm': 0.7842099666595459, 'learning_rate': 2.7299879807692307e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24553317112c491f9c32955232e07ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3283754587173462, 'eval_runtime': 21.9023, 'eval_samples_per_second': 57.026, 'eval_steps_per_second': 57.026, 'epoch': 0.9}\n",
      "{'loss': 0.4655, 'grad_norm': 1.1646045446395874, 'learning_rate': 2.699939903846154e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5aace688a65454bb71403a6aaf45ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4382343292236328, 'eval_runtime': 22.1576, 'eval_samples_per_second': 56.369, 'eval_steps_per_second': 56.369, 'epoch': 1.0}\n",
      "{'loss': 0.4965, 'grad_norm': 0.7365132570266724, 'learning_rate': 2.669891826923077e-05, 'epoch': 1.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e21dbbf8ee419995a494c49b1f982b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4554312527179718, 'eval_runtime': 21.8732, 'eval_samples_per_second': 57.102, 'eval_steps_per_second': 57.102, 'epoch': 1.1}\n",
      "{'loss': 0.4626, 'grad_norm': 12.034932136535645, 'learning_rate': 2.6398437500000004e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eb2f1775f84aa2baf03ac36fc7bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4630197286605835, 'eval_runtime': 21.9084, 'eval_samples_per_second': 57.01, 'eval_steps_per_second': 57.01, 'epoch': 1.2}\n",
      "{'loss': 0.464, 'grad_norm': 3.2634572982788086, 'learning_rate': 2.6098557692307692e-05, 'epoch': 1.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25caa351573247f9b547431ff57a5c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3272598087787628, 'eval_runtime': 22.309, 'eval_samples_per_second': 55.986, 'eval_steps_per_second': 55.986, 'epoch': 1.3}\n",
      "{'loss': 0.4645, 'grad_norm': 9.339091300964355, 'learning_rate': 2.5798076923076926e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faae7ea647e6479c82d1d955d337731b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4603619873523712, 'eval_runtime': 22.2978, 'eval_samples_per_second': 56.014, 'eval_steps_per_second': 56.014, 'epoch': 1.4}\n",
      "{'loss': 0.4632, 'grad_norm': 9.694141387939453, 'learning_rate': 2.5497596153846154e-05, 'epoch': 1.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5e14c17613465a8d8451203c07a06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4346650242805481, 'eval_runtime': 22.0343, 'eval_samples_per_second': 56.684, 'eval_steps_per_second': 56.684, 'epoch': 1.5}\n",
      "{'loss': 0.4749, 'grad_norm': 10.63216781616211, 'learning_rate': 2.5197115384615385e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8bc7c3460f4e9389c5b9482643ad1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36287644505500793, 'eval_runtime': 22.443, 'eval_samples_per_second': 55.652, 'eval_steps_per_second': 55.652, 'epoch': 1.6}\n",
      "{'loss': 0.4244, 'grad_norm': 11.440138816833496, 'learning_rate': 2.489723557692308e-05, 'epoch': 1.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe6d62b47584681bfa22a021d742556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3529011607170105, 'eval_runtime': 22.1025, 'eval_samples_per_second': 56.509, 'eval_steps_per_second': 56.509, 'epoch': 1.7}\n",
      "{'loss': 0.401, 'grad_norm': 0.27251631021499634, 'learning_rate': 2.4596754807692308e-05, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee3857230dd47b28c21cf61d79bb501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3890533149242401, 'eval_runtime': 22.3682, 'eval_samples_per_second': 55.838, 'eval_steps_per_second': 55.838, 'epoch': 1.8}\n",
      "{'loss': 0.4661, 'grad_norm': 0.22069890797138214, 'learning_rate': 2.429747596153846e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd19066d5d046e5a5c0e3eb1a8a5a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4156334698200226, 'eval_runtime': 21.9018, 'eval_samples_per_second': 57.027, 'eval_steps_per_second': 57.027, 'epoch': 1.9}\n",
      "{'loss': 0.43, 'grad_norm': 4.968319416046143, 'learning_rate': 2.399699519230769e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e872bd6da5b24e5b864a5ed591189e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4570123851299286, 'eval_runtime': 22.0035, 'eval_samples_per_second': 56.764, 'eval_steps_per_second': 56.764, 'epoch': 2.0}\n",
      "{'loss': 0.3871, 'grad_norm': 7.406917095184326, 'learning_rate': 2.3696514423076925e-05, 'epoch': 2.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ecc49202ef44819bb020a4cefb7e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4928951859474182, 'eval_runtime': 22.2541, 'eval_samples_per_second': 56.124, 'eval_steps_per_second': 56.124, 'epoch': 2.1}\n",
      "{'loss': 0.417, 'grad_norm': 5.651954650878906, 'learning_rate': 2.3396033653846156e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03697b0aece54e41b2d6dbea209ab09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49632444977760315, 'eval_runtime': 22.008, 'eval_samples_per_second': 56.752, 'eval_steps_per_second': 56.752, 'epoch': 2.2}\n",
      "{'loss': 0.4545, 'grad_norm': 17.239105224609375, 'learning_rate': 2.3095552884615384e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2868c6d732441dbad4d75d25065283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4592262804508209, 'eval_runtime': 21.9869, 'eval_samples_per_second': 56.807, 'eval_steps_per_second': 56.807, 'epoch': 2.3}\n",
      "{'loss': 0.4191, 'grad_norm': 21.191303253173828, 'learning_rate': 2.2795072115384615e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf186b96eca047ac922132c31bb54a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5099661350250244, 'eval_runtime': 22.0942, 'eval_samples_per_second': 56.531, 'eval_steps_per_second': 56.531, 'epoch': 2.4}\n",
      "{'loss': 0.4135, 'grad_norm': 13.316132545471191, 'learning_rate': 2.2494591346153846e-05, 'epoch': 2.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2462b139893647e19ef0366d258c674b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.517138659954071, 'eval_runtime': 21.9472, 'eval_samples_per_second': 56.909, 'eval_steps_per_second': 56.909, 'epoch': 2.5}\n",
      "{'loss': 0.439, 'grad_norm': 0.6280094981193542, 'learning_rate': 2.219411057692308e-05, 'epoch': 2.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708c9272e8234a3494611e5f71eb6452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5022063255310059, 'eval_runtime': 22.3432, 'eval_samples_per_second': 55.901, 'eval_steps_per_second': 55.901, 'epoch': 2.6}\n",
      "{'loss': 0.4646, 'grad_norm': 29.929990768432617, 'learning_rate': 2.1893629807692308e-05, 'epoch': 2.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2472dd50864cf5a1f6ab9219983cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5101897716522217, 'eval_runtime': 22.1245, 'eval_samples_per_second': 56.453, 'eval_steps_per_second': 56.453, 'epoch': 2.7}\n",
      "{'loss': 0.4927, 'grad_norm': 17.922956466674805, 'learning_rate': 2.159314903846154e-05, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a881c095d04f4fd5b8ed613a373d676d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5237619876861572, 'eval_runtime': 21.8427, 'eval_samples_per_second': 57.182, 'eval_steps_per_second': 57.182, 'epoch': 2.8}\n",
      "{'loss': 0.4743, 'grad_norm': 2.944620132446289, 'learning_rate': 2.129326923076923e-05, 'epoch': 2.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fe9ecacc294fd592685562e637b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4992309808731079, 'eval_runtime': 22.5948, 'eval_samples_per_second': 55.278, 'eval_steps_per_second': 55.278, 'epoch': 2.9}\n",
      "{'loss': 0.4184, 'grad_norm': 22.65220832824707, 'learning_rate': 2.0992788461538462e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edddeb31196148c48c87b0d825f9ff41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5322273969650269, 'eval_runtime': 22.0966, 'eval_samples_per_second': 56.525, 'eval_steps_per_second': 56.525, 'epoch': 3.0}\n",
      "{'loss': 0.4488, 'grad_norm': 24.40729331970215, 'learning_rate': 2.0692307692307693e-05, 'epoch': 3.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d8f9bd4ff04fe59af53e2f3c2899d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.502545177936554, 'eval_runtime': 21.9384, 'eval_samples_per_second': 56.932, 'eval_steps_per_second': 56.932, 'epoch': 3.1}\n",
      "{'loss': 0.3878, 'grad_norm': 21.42656135559082, 'learning_rate': 2.0391826923076924e-05, 'epoch': 3.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da38f9b6e91d4601a46efad33d604e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5770018100738525, 'eval_runtime': 22.2907, 'eval_samples_per_second': 56.032, 'eval_steps_per_second': 56.032, 'epoch': 3.21}\n",
      "{'loss': 0.4307, 'grad_norm': 16.60619354248047, 'learning_rate': 2.0091947115384615e-05, 'epoch': 3.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7928e62453da4073abe0d3a8b67d8244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.594901978969574, 'eval_runtime': 21.909, 'eval_samples_per_second': 57.009, 'eval_steps_per_second': 57.009, 'epoch': 3.31}\n",
      "{'loss': 0.4472, 'grad_norm': 7.1486711502075195, 'learning_rate': 1.9791466346153846e-05, 'epoch': 3.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87d833a414d4908ada7fd0d35acf23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5911118388175964, 'eval_runtime': 22.0002, 'eval_samples_per_second': 56.772, 'eval_steps_per_second': 56.772, 'epoch': 3.41}\n",
      "{'loss': 0.4543, 'grad_norm': 21.204547882080078, 'learning_rate': 1.9490985576923077e-05, 'epoch': 3.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241cf7a3801147e283949bfb92f54312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5790989995002747, 'eval_runtime': 22.1235, 'eval_samples_per_second': 56.456, 'eval_steps_per_second': 56.456, 'epoch': 3.51}\n",
      "{'loss': 0.441, 'grad_norm': 15.70605182647705, 'learning_rate': 1.919050480769231e-05, 'epoch': 3.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a10266c49446c4a745c90bfe01eb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6186304688453674, 'eval_runtime': 22.0185, 'eval_samples_per_second': 56.725, 'eval_steps_per_second': 56.725, 'epoch': 3.61}\n",
      "{'loss': 0.4583, 'grad_norm': 32.96261215209961, 'learning_rate': 1.889002403846154e-05, 'epoch': 3.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060d77c5b80c4c0eb42a227f21e53273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6114766597747803, 'eval_runtime': 22.339, 'eval_samples_per_second': 55.911, 'eval_steps_per_second': 55.911, 'epoch': 3.71}\n",
      "{'loss': 0.4371, 'grad_norm': 24.203201293945312, 'learning_rate': 1.859014423076923e-05, 'epoch': 3.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d4b0a5a376430ca42637cf6f48d1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5770112872123718, 'eval_runtime': 21.8059, 'eval_samples_per_second': 57.278, 'eval_steps_per_second': 57.278, 'epoch': 3.81}\n",
      "{'loss': 0.4257, 'grad_norm': 21.992900848388672, 'learning_rate': 1.8289663461538462e-05, 'epoch': 3.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de123ed28304a189e806d26b354ebed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6046270728111267, 'eval_runtime': 22.2074, 'eval_samples_per_second': 56.243, 'eval_steps_per_second': 56.243, 'epoch': 3.91}\n",
      "{'loss': 0.4601, 'grad_norm': 3.0674216747283936, 'learning_rate': 1.7989182692307693e-05, 'epoch': 4.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3488801e1d5149469bc27b47de156571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.596476674079895, 'eval_runtime': 22.2159, 'eval_samples_per_second': 56.221, 'eval_steps_per_second': 56.221, 'epoch': 4.01}\n",
      "{'loss': 0.411, 'grad_norm': 0.20815302431583405, 'learning_rate': 1.7688701923076924e-05, 'epoch': 4.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cc33058a33443095e1ef68f15b3615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5965874791145325, 'eval_runtime': 22.0798, 'eval_samples_per_second': 56.568, 'eval_steps_per_second': 56.568, 'epoch': 4.11}\n",
      "{'loss': 0.4728, 'grad_norm': 30.895212173461914, 'learning_rate': 1.7388822115384616e-05, 'epoch': 4.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b42859a6df447aba7ac7fa4affc53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5780961513519287, 'eval_runtime': 21.913, 'eval_samples_per_second': 56.998, 'eval_steps_per_second': 56.998, 'epoch': 4.21}\n",
      "{'loss': 0.4356, 'grad_norm': 13.051544189453125, 'learning_rate': 1.7088341346153847e-05, 'epoch': 4.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27411833969a4eebba5f6db004224ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6502951383590698, 'eval_runtime': 21.9388, 'eval_samples_per_second': 56.931, 'eval_steps_per_second': 56.931, 'epoch': 4.31}\n",
      "{'loss': 0.4164, 'grad_norm': 0.314775675535202, 'learning_rate': 1.6787860576923078e-05, 'epoch': 4.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b9785d36954dc7acd486c83a32a9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6304618120193481, 'eval_runtime': 21.9841, 'eval_samples_per_second': 56.814, 'eval_steps_per_second': 56.814, 'epoch': 4.41}\n",
      "{'loss': 0.4585, 'grad_norm': 23.99639320373535, 'learning_rate': 1.6487379807692305e-05, 'epoch': 4.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516381f3bcd54982a5b550e3ef447911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6354663372039795, 'eval_runtime': 22.2945, 'eval_samples_per_second': 56.023, 'eval_steps_per_second': 56.023, 'epoch': 4.51}\n",
      "{'loss': 0.4384, 'grad_norm': 0.6628952026367188, 'learning_rate': 1.61875e-05, 'epoch': 4.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d33f6b581a4bc28b9929b7721794cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6884129643440247, 'eval_runtime': 22.0866, 'eval_samples_per_second': 56.55, 'eval_steps_per_second': 56.55, 'epoch': 4.61}\n",
      "{'loss': 0.43, 'grad_norm': 17.30394172668457, 'learning_rate': 1.5887019230769228e-05, 'epoch': 4.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c610dbe79ae45c199fd9f5a23e8f3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6760469079017639, 'eval_runtime': 22.0365, 'eval_samples_per_second': 56.679, 'eval_steps_per_second': 56.679, 'epoch': 4.71}\n",
      "{'loss': 0.4914, 'grad_norm': 0.911189079284668, 'learning_rate': 1.5586538461538462e-05, 'epoch': 4.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21da3224723342988cf8eeb19840993c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6154776215553284, 'eval_runtime': 22.1744, 'eval_samples_per_second': 56.326, 'eval_steps_per_second': 56.326, 'epoch': 4.81}\n",
      "{'loss': 0.3856, 'grad_norm': 11.123381614685059, 'learning_rate': 1.5286057692307694e-05, 'epoch': 4.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c972e63f1e4315903d684da87cd2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6375555396080017, 'eval_runtime': 22.022, 'eval_samples_per_second': 56.716, 'eval_steps_per_second': 56.716, 'epoch': 4.91}\n",
      "{'loss': 0.4351, 'grad_norm': 2.7392871379852295, 'learning_rate': 1.4986177884615385e-05, 'epoch': 5.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8943c005f89643d1a2afd0bb6b41cbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6614298224449158, 'eval_runtime': 21.9326, 'eval_samples_per_second': 56.947, 'eval_steps_per_second': 56.947, 'epoch': 5.01}\n",
      "{'loss': 0.4605, 'grad_norm': 3.65012526512146, 'learning_rate': 1.4685697115384616e-05, 'epoch': 5.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd58440740943039b7d0dd09506a6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6181291937828064, 'eval_runtime': 22.0192, 'eval_samples_per_second': 56.723, 'eval_steps_per_second': 56.723, 'epoch': 5.11}\n",
      "{'loss': 0.4123, 'grad_norm': 1.5037472248077393, 'learning_rate': 1.4385216346153847e-05, 'epoch': 5.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a281356aaf346e69d85ce80b3eb84e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6514842510223389, 'eval_runtime': 21.9806, 'eval_samples_per_second': 56.823, 'eval_steps_per_second': 56.823, 'epoch': 5.21}\n",
      "{'loss': 0.4502, 'grad_norm': 7.10018253326416, 'learning_rate': 1.4084735576923076e-05, 'epoch': 5.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def547c04b3f41bd8b8f8ad531233368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6194990873336792, 'eval_runtime': 22.2158, 'eval_samples_per_second': 56.221, 'eval_steps_per_second': 56.221, 'epoch': 5.31}\n",
      "{'loss': 0.4169, 'grad_norm': 0.8300756216049194, 'learning_rate': 1.378425480769231e-05, 'epoch': 5.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67bcff06bcd4fd7a41e7c5142a5b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6706216335296631, 'eval_runtime': 22.2043, 'eval_samples_per_second': 56.25, 'eval_steps_per_second': 56.25, 'epoch': 5.41}\n",
      "{'loss': 0.4521, 'grad_norm': 0.03473956137895584, 'learning_rate': 1.3484374999999999e-05, 'epoch': 5.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e230b475656a4070a72b5b156d777ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6473796963691711, 'eval_runtime': 21.7941, 'eval_samples_per_second': 57.309, 'eval_steps_per_second': 57.309, 'epoch': 5.51}\n",
      "{'loss': 0.3964, 'grad_norm': 21.584869384765625, 'learning_rate': 1.3183894230769232e-05, 'epoch': 5.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0909f669759407f9084b9ccd9482000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6779866218566895, 'eval_runtime': 22.206, 'eval_samples_per_second': 56.246, 'eval_steps_per_second': 56.246, 'epoch': 5.61}\n",
      "{'loss': 0.4101, 'grad_norm': 0.17757649719715118, 'learning_rate': 1.2883413461538461e-05, 'epoch': 5.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567d75096a0149e69dd19856cd748c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.676101565361023, 'eval_runtime': 21.9693, 'eval_samples_per_second': 56.852, 'eval_steps_per_second': 56.852, 'epoch': 5.71}\n",
      "{'loss': 0.4308, 'grad_norm': 31.48599624633789, 'learning_rate': 1.2582932692307692e-05, 'epoch': 5.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37539069b9a04fd28dbdd694317afddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7042039632797241, 'eval_runtime': 21.9207, 'eval_samples_per_second': 56.978, 'eval_steps_per_second': 56.978, 'epoch': 5.81}\n",
      "{'loss': 0.4236, 'grad_norm': 5.302909851074219, 'learning_rate': 1.2283052884615385e-05, 'epoch': 5.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a952a87fefc4ec99343136df1703d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6749285459518433, 'eval_runtime': 21.9768, 'eval_samples_per_second': 56.833, 'eval_steps_per_second': 56.833, 'epoch': 5.91}\n",
      "{'loss': 0.4483, 'grad_norm': 13.491842269897461, 'learning_rate': 1.1982572115384615e-05, 'epoch': 6.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e555dfd76dfd4d3b8207a4e754742afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7090458273887634, 'eval_runtime': 22.1546, 'eval_samples_per_second': 56.377, 'eval_steps_per_second': 56.377, 'epoch': 6.01}\n",
      "{'loss': 0.408, 'grad_norm': 27.98006248474121, 'learning_rate': 1.1682091346153848e-05, 'epoch': 6.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cdb4cb6319341b39653b64d5df67f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7063722014427185, 'eval_runtime': 22.2914, 'eval_samples_per_second': 56.031, 'eval_steps_per_second': 56.031, 'epoch': 6.11}\n",
      "{'loss': 0.3901, 'grad_norm': 6.035536766052246, 'learning_rate': 1.1381610576923077e-05, 'epoch': 6.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1a3b46509f4f16abe4865fbf4d5bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7018461227416992, 'eval_runtime': 22.0611, 'eval_samples_per_second': 56.615, 'eval_steps_per_second': 56.615, 'epoch': 6.21}\n",
      "{'loss': 0.4074, 'grad_norm': 6.94213342666626, 'learning_rate': 1.108173076923077e-05, 'epoch': 6.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73aede0d97bb4753958cbb0bfb27411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6828694343566895, 'eval_runtime': 22.0458, 'eval_samples_per_second': 56.655, 'eval_steps_per_second': 56.655, 'epoch': 6.31}\n",
      "{'loss': 0.4138, 'grad_norm': 16.285579681396484, 'learning_rate': 1.078125e-05, 'epoch': 6.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831e76f7e9794ae59f2d908f28de8388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7723380923271179, 'eval_runtime': 22.2731, 'eval_samples_per_second': 56.077, 'eval_steps_per_second': 56.077, 'epoch': 6.41}\n",
      "{'loss': 0.4406, 'grad_norm': 0.3997447192668915, 'learning_rate': 1.048076923076923e-05, 'epoch': 6.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ff1c2fe8ae479aa34e8d8d1d59fbde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.703401505947113, 'eval_runtime': 22.0481, 'eval_samples_per_second': 56.649, 'eval_steps_per_second': 56.649, 'epoch': 6.51}\n",
      "{'loss': 0.481, 'grad_norm': 20.122997283935547, 'learning_rate': 1.0180288461538462e-05, 'epoch': 6.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f9e3218bea4fcbb7cd081a6117708b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6640209555625916, 'eval_runtime': 22.0892, 'eval_samples_per_second': 56.543, 'eval_steps_per_second': 56.543, 'epoch': 6.61}\n",
      "{'loss': 0.4034, 'grad_norm': 8.880927085876465, 'learning_rate': 9.880408653846153e-06, 'epoch': 6.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670d6842978f4d85a328d77c1edec5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6927049160003662, 'eval_runtime': 21.999, 'eval_samples_per_second': 56.775, 'eval_steps_per_second': 56.775, 'epoch': 6.71}\n",
      "{'loss': 0.4816, 'grad_norm': 0.09294828027486801, 'learning_rate': 9.579927884615386e-06, 'epoch': 6.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71b51083aa94fb1975dbd7ae5452ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6966079473495483, 'eval_runtime': 21.8333, 'eval_samples_per_second': 57.206, 'eval_steps_per_second': 57.206, 'epoch': 6.81}\n",
      "{'loss': 0.4156, 'grad_norm': 38.10234832763672, 'learning_rate': 9.279447115384615e-06, 'epoch': 6.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd2b08b2d4c4f7bbdab08336c12aef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6846146583557129, 'eval_runtime': 22.08, 'eval_samples_per_second': 56.567, 'eval_steps_per_second': 56.567, 'epoch': 6.91}\n",
      "{'loss': 0.4612, 'grad_norm': 19.636178970336914, 'learning_rate': 8.978966346153846e-06, 'epoch': 7.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e622c44f3c1647d5b5229ef79504a5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6813660860061646, 'eval_runtime': 22.0529, 'eval_samples_per_second': 56.637, 'eval_steps_per_second': 56.637, 'epoch': 7.01}\n",
      "{'loss': 0.4512, 'grad_norm': 0.06610029935836792, 'learning_rate': 8.67908653846154e-06, 'epoch': 7.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42aec3d8e637419e92d7ee57cfae1f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7023696303367615, 'eval_runtime': 22.046, 'eval_samples_per_second': 56.654, 'eval_steps_per_second': 56.654, 'epoch': 7.11}\n",
      "{'loss': 0.429, 'grad_norm': 0.08186301589012146, 'learning_rate': 8.378605769230769e-06, 'epoch': 7.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9c1ca9ef144f1b8cf2cf037f5b35bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7232782244682312, 'eval_runtime': 22.2385, 'eval_samples_per_second': 56.164, 'eval_steps_per_second': 56.164, 'epoch': 7.21}\n",
      "{'loss': 0.3776, 'grad_norm': 0.12057949602603912, 'learning_rate': 8.078125e-06, 'epoch': 7.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090471668ae4f7c981ea3839253e9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7290324568748474, 'eval_runtime': 22.1306, 'eval_samples_per_second': 56.438, 'eval_steps_per_second': 56.438, 'epoch': 7.31}\n",
      "{'loss': 0.4154, 'grad_norm': 0.43057775497436523, 'learning_rate': 7.777644230769231e-06, 'epoch': 7.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3025f905394b2d8ea830d4d38d54fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6977748274803162, 'eval_runtime': 22.033, 'eval_samples_per_second': 56.688, 'eval_steps_per_second': 56.688, 'epoch': 7.41}\n",
      "{'loss': 0.4094, 'grad_norm': 0.3874826431274414, 'learning_rate': 7.477764423076923e-06, 'epoch': 7.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ef9833eb994b4a8e15d2edd929d65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7344380021095276, 'eval_runtime': 21.9719, 'eval_samples_per_second': 56.845, 'eval_steps_per_second': 56.845, 'epoch': 7.51}\n",
      "{'loss': 0.4449, 'grad_norm': 2.303772449493408, 'learning_rate': 7.177283653846154e-06, 'epoch': 7.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b62b7122b9644bea58ce32fe518a5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7180905342102051, 'eval_runtime': 21.9357, 'eval_samples_per_second': 56.939, 'eval_steps_per_second': 56.939, 'epoch': 7.61}\n",
      "{'loss': 0.4103, 'grad_norm': 29.05681610107422, 'learning_rate': 6.8768028846153845e-06, 'epoch': 7.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664eb031604e48a59641f8d58249e08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7321071624755859, 'eval_runtime': 21.9405, 'eval_samples_per_second': 56.927, 'eval_steps_per_second': 56.927, 'epoch': 7.71}\n",
      "{'loss': 0.4792, 'grad_norm': 24.3717041015625, 'learning_rate': 6.5763221153846155e-06, 'epoch': 7.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1fe7c44d6f4483acc9a45a32efc736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7167288661003113, 'eval_runtime': 21.8527, 'eval_samples_per_second': 57.155, 'eval_steps_per_second': 57.155, 'epoch': 7.81}\n",
      "{'loss': 0.4459, 'grad_norm': 0.044593628495931625, 'learning_rate': 6.276442307692308e-06, 'epoch': 7.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f4832b157e4b0d91581806a4d6142c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6919227242469788, 'eval_runtime': 22.3275, 'eval_samples_per_second': 55.94, 'eval_steps_per_second': 55.94, 'epoch': 7.91}\n",
      "{'loss': 0.4051, 'grad_norm': 21.050241470336914, 'learning_rate': 5.975961538461538e-06, 'epoch': 8.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33fd1f33d624f2ba36469ac0c8195f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7503241896629333, 'eval_runtime': 22.229, 'eval_samples_per_second': 56.188, 'eval_steps_per_second': 56.188, 'epoch': 8.01}\n",
      "{'loss': 0.4172, 'grad_norm': 19.936941146850586, 'learning_rate': 5.675480769230769e-06, 'epoch': 8.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a7b5297bee42249bead3cf00d9046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7118529081344604, 'eval_runtime': 22.0121, 'eval_samples_per_second': 56.741, 'eval_steps_per_second': 56.741, 'epoch': 8.11}\n",
      "{'loss': 0.4483, 'grad_norm': 8.370477676391602, 'learning_rate': 5.375e-06, 'epoch': 8.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee06eceac44fdbb001e598048cee24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7177258133888245, 'eval_runtime': 21.957, 'eval_samples_per_second': 56.884, 'eval_steps_per_second': 56.884, 'epoch': 8.21}\n",
      "{'loss': 0.3839, 'grad_norm': 4.3004841804504395, 'learning_rate': 5.074519230769231e-06, 'epoch': 8.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17fbc8c1edf4be48b679f8da78592d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7099173069000244, 'eval_runtime': 21.9688, 'eval_samples_per_second': 56.853, 'eval_steps_per_second': 56.853, 'epoch': 8.31}\n",
      "{'loss': 0.3724, 'grad_norm': 26.29486656188965, 'learning_rate': 4.774639423076924e-06, 'epoch': 8.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48bdd21f8ebe42c49725800135219e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7491852641105652, 'eval_runtime': 22.3609, 'eval_samples_per_second': 55.856, 'eval_steps_per_second': 55.856, 'epoch': 8.41}\n",
      "{'loss': 0.4343, 'grad_norm': 24.399307250976562, 'learning_rate': 4.474158653846155e-06, 'epoch': 8.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1fa2fe0616424ab0217aa9fd1b988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7343939542770386, 'eval_runtime': 22.0142, 'eval_samples_per_second': 56.736, 'eval_steps_per_second': 56.736, 'epoch': 8.51}\n",
      "{'loss': 0.4534, 'grad_norm': 4.7399210929870605, 'learning_rate': 4.173677884615385e-06, 'epoch': 8.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded3cd742e7e4e7980efea45085f8e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7152500152587891, 'eval_runtime': 22.2836, 'eval_samples_per_second': 56.05, 'eval_steps_per_second': 56.05, 'epoch': 8.61}\n",
      "{'loss': 0.4303, 'grad_norm': 0.06552407890558243, 'learning_rate': 3.873197115384615e-06, 'epoch': 8.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3e3e15f3b14028a12bd3dfccb6bff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6990986466407776, 'eval_runtime': 21.9963, 'eval_samples_per_second': 56.782, 'eval_steps_per_second': 56.782, 'epoch': 8.71}\n",
      "{'loss': 0.4362, 'grad_norm': 2.22381854057312, 'learning_rate': 3.5733173076923075e-06, 'epoch': 8.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fc348090a14a3598357a3041b801a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7204425930976868, 'eval_runtime': 22.5087, 'eval_samples_per_second': 55.49, 'eval_steps_per_second': 55.49, 'epoch': 8.81}\n",
      "{'loss': 0.3918, 'grad_norm': 16.131868362426758, 'learning_rate': 3.2728365384615385e-06, 'epoch': 8.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5438399407e64426a9e3ed8e67357b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7408996820449829, 'eval_runtime': 21.9153, 'eval_samples_per_second': 56.992, 'eval_steps_per_second': 56.992, 'epoch': 8.91}\n",
      "{'loss': 0.4426, 'grad_norm': 2.1150801181793213, 'learning_rate': 2.972355769230769e-06, 'epoch': 9.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532f66df348145369923ed304d6c5269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7247517704963684, 'eval_runtime': 22.0853, 'eval_samples_per_second': 56.554, 'eval_steps_per_second': 56.554, 'epoch': 9.01}\n",
      "{'loss': 0.4058, 'grad_norm': 34.52687454223633, 'learning_rate': 2.671875e-06, 'epoch': 9.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b0678bf2a04980ab2d5353f0df886d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7186013460159302, 'eval_runtime': 22.3596, 'eval_samples_per_second': 55.86, 'eval_steps_per_second': 55.86, 'epoch': 9.11}\n",
      "{'loss': 0.4265, 'grad_norm': 0.031829506158828735, 'learning_rate': 2.371995192307692e-06, 'epoch': 9.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1648f5ec2f1f4f46bd11215ed0d82d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7187245488166809, 'eval_runtime': 21.8401, 'eval_samples_per_second': 57.188, 'eval_steps_per_second': 57.188, 'epoch': 9.21}\n",
      "{'loss': 0.4272, 'grad_norm': 27.492788314819336, 'learning_rate': 2.071514423076923e-06, 'epoch': 9.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adaba1889614781b81fb8ab4da171c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7267150282859802, 'eval_runtime': 22.2912, 'eval_samples_per_second': 56.031, 'eval_steps_per_second': 56.031, 'epoch': 9.31}\n",
      "{'loss': 0.43, 'grad_norm': 23.963422775268555, 'learning_rate': 1.7710336538461538e-06, 'epoch': 9.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4bf69358d245c1ac46a6be545ad364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7317846417427063, 'eval_runtime': 22.3081, 'eval_samples_per_second': 55.989, 'eval_steps_per_second': 55.989, 'epoch': 9.42}\n",
      "{'loss': 0.4667, 'grad_norm': 28.927635192871094, 'learning_rate': 1.4705528846153846e-06, 'epoch': 9.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7640ed9d82614bafa790538c3474d876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7313274145126343, 'eval_runtime': 21.9946, 'eval_samples_per_second': 56.787, 'eval_steps_per_second': 56.787, 'epoch': 9.52}\n",
      "{'loss': 0.3634, 'grad_norm': 0.4396069645881653, 'learning_rate': 1.170673076923077e-06, 'epoch': 9.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6325de9e614ed391356d0b434dabf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7470300197601318, 'eval_runtime': 22.3419, 'eval_samples_per_second': 55.904, 'eval_steps_per_second': 55.904, 'epoch': 9.62}\n",
      "{'loss': 0.4791, 'grad_norm': 27.615554809570312, 'learning_rate': 8.701923076923078e-07, 'epoch': 9.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8308861a7a364167ba68f7cbfc74dc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.739204466342926, 'eval_runtime': 22.1032, 'eval_samples_per_second': 56.508, 'eval_steps_per_second': 56.508, 'epoch': 9.72}\n",
      "{'loss': 0.3898, 'grad_norm': 30.569196701049805, 'learning_rate': 5.697115384615385e-07, 'epoch': 9.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fee5db51204896874592ad42073d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7406260967254639, 'eval_runtime': 21.909, 'eval_samples_per_second': 57.009, 'eval_steps_per_second': 57.009, 'epoch': 9.82}\n",
      "{'loss': 0.4384, 'grad_norm': 4.763878345489502, 'learning_rate': 2.692307692307692e-07, 'epoch': 9.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37b659ea7d14c9ab64231d443a20770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7377873063087463, 'eval_runtime': 22.1981, 'eval_samples_per_second': 56.266, 'eval_steps_per_second': 56.266, 'epoch': 9.92}\n",
      "{'train_runtime': 6253.5418, 'train_samples_per_second': 7.983, 'train_steps_per_second': 7.983, 'train_loss': 0.45593070066892183, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=49920, training_loss=0.45593070066892183, metrics={'train_runtime': 6253.5418, 'train_samples_per_second': 7.983, 'train_steps_per_second': 7.983, 'total_flos': 6756262729482240.0, 'train_loss': 0.45593070066892183, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Load the T5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./t5-fit-level\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-5,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Enable mixed precision if you have GPU\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training result\n",
    "The fine-tuned T5-small model achieved a training loss of 0.456, indicating that it effectively learned patterns from the training data while minimizing prediction errors. Over the course of 10 epochs, the model completed 49,920 steps, processing approximately 8 samples per second, which demonstrates efficient utilization of computational resources. The reported floating-point operations (FLOPs) totaled approximately 6.76 quadrillion, highlighting the computational intensity of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Michael\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Michael\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\transformers\\generation\\utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict(job_description, resume):\n",
    "    input_text = (f\"Evaluate the fit level of the following resume for the job description: \"\n",
    "                  f\"Job Description: {job_description} \"\n",
    "                  f\"Resume: {resume}\")\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(input_ids,top_p=0.9)\n",
    "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return prediction\n",
    "\n",
    "# Example prediction\n",
    "job_description = \"Software Engineer with experience in Python and cloud computing.\"\n",
    "resume = \"Experienced developer with expertise in Python, AWS, and software design.\"\n",
    "print(predict(job_description, resume))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job description Parsing\n",
    "\n",
    "Here we will use Optical Character Recognition with the PaddleOCR library to extract text from an image. It initializes the PaddleOCR object. The ocr method processes the given image path and returns a structured result, from which the function extracts only the recognized text (ignoring bounding box data and confidence scores). The extracted text is concatenated into a single string and returned, providing a readable transcription of the text present in the image. This is particularly useful for converting job description images into machine-readable text for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# Set tesseract_cmd to the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"c:\\users\\michael\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/07 14:44:06] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, formula=False, formula_algorithm='LaTeXOCR', formula_batch_num=1, formula_char_dict_path=None, formula_model_dir=None, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='ch', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='C:\\\\Users\\\\Michael\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', recovery=False, recovery_to_markdown=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', savefile=False, scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=False, use_dilation=False, use_gpu=False, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2024/12/07 14:44:07] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/07 14:44:07] ppocr DEBUG: dt_boxes num : 50, elapsed : 0.38599729537963867\n",
      "[2024/12/07 14:44:10] ppocr DEBUG: rec_res num  : 50, elapsed : 2.9961154460906982\n",
      "Ibotta Internet &Software (#R-101567)MachineLearningIntern Posted 2 months ago - Apply by December 16, 2024 at 7 AM Save ApplyExternally Ata glance $30-40/hr Hybridoronsite,basedinDenver, Work in person for part or all of the week, from the location bInternship Full-tinme - From May 19 to August 29 US work authorizationrequired Ibotta is seeking a Machine Learning Intern to join our innovative team and contribute to our mission to Make Every Purchase Rewarding. As a participant in our 2025 Summer Internship. you will have the opportunity to full integrate with your team to directly contribute to ongoing Ibotta business initiatives. In addifion to the daily time with your team, you will participate in ongoing teach outs curated to help build skils essenfal to transitioning into the workforce and building your career. We are looking for candidates who are eagerto learn, excited to work on realworld business challenges, and want to be part of a mission- diven company. This will be a full-fime, 12 week, intemship during the summer of 2025. This is a hybrid position located in Denver, Colorado and requires 3 days in-office per week. Required in- office hybid days are Tuesday. Wednesday, and Thursday. Candidates must Iive in the United States. What you will be doing: Work with the mentor on understanding our models, users and clients. Build, train, and validate deep learning recommender, and reinforcement learning Run statisfcal analysis and create predictive models based on past user purchases and behavior Develop recommender s/stems and machine learning algorithms for usertargeting and personalization Build welltested, maintainable, and extendable code Report and understand system performance in detail and identify ideas for improvement Embrace and uphold Ibotta's Core Values: Integrity Boldnes, Ownership, Teamwork, Transparengy & A good idea can come from anywhere What we are looking for: Juniors working towards a bachelor's degree with a focus in Computer Science, Engineering, Data Analytics or a related field Proven abity to think creatively and implement ideas from start to finish Good written and verbal communication skills Hunger to learn and collaborate with your teammates Good understanding ofthe key concepts of Recommender Systems and Machine Leaming Proven expertise with data handling. processing, statistical and anal/tical skills Python experience is required, as wellas experience with either Tensorflow or PyTorch Spark/PySpark experience is an additional plus Abilty to develop and maintain ML modek, in addition to being able to visuaize, analyze, and communicate results Experience with SQ,L required Good understanding of A/B testing and control group concepts\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "def extract_text_with_paddleocr(image_path):\n",
    "    ocr = PaddleOCR()  # Initialize PaddleOCR\n",
    "    results = ocr.ocr(image_path)\n",
    "    text = [line[1][0] for line in results[0]]  # Extract the text content\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Example Usage\n",
    "job_description = extract_text_with_paddleocr(\"images/job_description_image.jpg\")\n",
    "print(job_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extracts all text from a given PDF file using the PyPDF2 library. It initializes a PdfReader object to read the PDF, iterates through each page, and appends the extracted text to a string variable. Finally, the function returns the concatenated text, providing a plain-text representation of the entire resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "# Extract original resume text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    resume_text = \"\"\n",
    "    for page in reader.pages:\n",
    "        resume_text += page.extract_text()\n",
    "    return resume_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Resume\n",
    " Here we atempt to create a tailored resume. We provide an input prompt combining the job description and the original resume, instructing the model to generate a tailored version. The prompt is tokenized into a format suitable for the model and transferred to a GPU for faster processing. Using the model's generate method, it produces a single output sequence, ensuring the response stays within a specified maximum length of 512 tokens. Finally, the generated text is decoded into a readable format and returned as the tailored resume, optimized for the provided job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a tailored resume based on the job description and original resume\n",
    "def generate_matching_resume(job_description, resume_text):\n",
    "    # Construct the input prompt for the model\n",
    "    input_text = (\n",
    "        f\"Generate a tailored Resume\\n\\n\"\n",
    "        f\"Job Description: {job_description}\\n\\n\"\n",
    "        f\"Original Resume: {resume_text}\"\n",
    "    )\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
    "    \n",
    "    # Generate the tailored resume\n",
    "    outputs = model.generate(input_ids, max_length=512, num_return_sequences=1)\n",
    "    tailored_resume = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return tailored_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/07 14:45:44] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, formula=False, formula_algorithm='LaTeXOCR', formula_batch_num=1, formula_char_dict_path=None, formula_model_dir=None, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='ch', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='C:\\\\Users\\\\Michael\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='C:\\\\Users\\\\Michael/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', recovery=False, recovery_to_markdown=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', savefile=False, scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=False, use_dilation=False, use_gpu=False, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2024/12/07 14:45:45] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/07 14:45:45] ppocr DEBUG: dt_boxes num : 50, elapsed : 0.10599732398986816\n",
      "[2024/12/07 14:45:47] ppocr DEBUG: rec_res num  : 50, elapsed : 2.3674988746643066\n",
      "Extracted Job Description:\n",
      "Ibotta Internet &Software (#R-101567)MachineLearningIntern Posted 2 months ago - Apply by December 16, 2024 at 7 AM Save ApplyExternally Ata glance $30-40/hr Hybridoronsite,basedinDenver, Work in person for part or all of the week, from the location bInternship Full-tinme - From May 19 to August 29 US work authorizationrequired Ibotta is seeking a Machine Learning Intern to join our innovative team and contribute to our mission to Make Every Purchase Rewarding. As a participant in our 2025 Summer Internship. you will have the opportunity to full integrate with your team to directly contribute to ongoing Ibotta business initiatives. In addifion to the daily time with your team, you will participate in ongoing teach outs curated to help build skils essenfal to transitioning into the workforce and building your career. We are looking for candidates who are eagerto learn, excited to work on realworld business challenges, and want to be part of a mission- diven company. This will be a full-fime, 12 week, intemship during the summer of 2025. This is a hybrid position located in Denver, Colorado and requires 3 days in-office per week. Required in- office hybid days are Tuesday. Wednesday, and Thursday. Candidates must Iive in the United States. What you will be doing: Work with the mentor on understanding our models, users and clients. Build, train, and validate deep learning recommender, and reinforcement learning Run statisfcal analysis and create predictive models based on past user purchases and behavior Develop recommender s/stems and machine learning algorithms for usertargeting and personalization Build welltested, maintainable, and extendable code Report and understand system performance in detail and identify ideas for improvement Embrace and uphold Ibotta's Core Values: Integrity Boldnes, Ownership, Teamwork, Transparengy & A good idea can come from anywhere What we are looking for: Juniors working towards a bachelor's degree with a focus in Computer Science, Engineering, Data Analytics or a related field Proven abity to think creatively and implement ideas from start to finish Good written and verbal communication skills Hunger to learn and collaborate with your teammates Good understanding ofthe key concepts of Recommender Systems and Machine Leaming Proven expertise with data handling. processing, statistical and anal/tical skills Python experience is required, as wellas experience with either Tensorflow or PyTorch Spark/PySpark experience is an additional plus Abilty to develop and maintain ML modek, in addition to being able to visuaize, analyze, and communicate results Experience with SQ,L required Good understanding of A/B testing and control group concepts\n",
      "\n",
      "Extracted Original Resume Text:\n",
      "Michael\n",
      "Haidar\n",
      "626-665-5278\n",
      "|\n",
      "michael.a.haidar.@vanderbilt.edu\n",
      "|\n",
      "LinkedIn\n",
      "EDUCATION\n",
      "Vanderbilt\n",
      "University\n",
      "–\n",
      "Data\n",
      "Science\n",
      "Institute\n",
      "Nashville,\n",
      "TN \n",
      "Master\n",
      "of\n",
      "Science\n",
      "in\n",
      "Data\n",
      "Science\n",
      "August\n",
      "2024\n",
      "–\n",
      "May\n",
      "2026 \n",
      "●\n",
      "Relevant\n",
      "Coursework:\n",
      "Probability\n",
      "and\n",
      "Statistical\n",
      "Inference,\n",
      "Data\n",
      "Science\n",
      "Algorithms,\n",
      "Generative\n",
      "AI\n",
      "Models\n",
      "California\n",
      "State\n",
      "University,\n",
      "Monterey\n",
      "Bay\n",
      "Seaside,\n",
      "CA \n",
      "Bachelor\n",
      "of\n",
      "Science\n",
      "(GPA:\n",
      "3.5/4.0)\n",
      "August\n",
      "2017\n",
      "–\n",
      "May\n",
      "2022 \n",
      "Majors:\n",
      "Computer\n",
      "Science\n",
      "&\n",
      "Psychology\n",
      "Minor:\n",
      "Mathematics \n",
      "●\n",
      "Dean’s\n",
      "List\n",
      "(2018-2022)\n",
      "|\n",
      "iOS\n",
      "App\n",
      "Competition\n",
      "Winner\n",
      "2019 \n",
      "●\n",
      "Relevant\n",
      "Coursework:\n",
      "Advanced\n",
      "Machine\n",
      "Learning,\n",
      "Advanced\n",
      "Linear\n",
      "Algebra,\n",
      "Applied\n",
      "Probability,\n",
      "Non-Parametric \n",
      "Statistics,\n",
      "Calculus\n",
      "1-3,\n",
      "Discrete\n",
      "Mathematics,\n",
      "Software\n",
      "Engineering,\n",
      "Design\n",
      "and\n",
      "Analysis\n",
      "of\n",
      "Algorithms,\n",
      "Differential \n",
      "Equations\n",
      "and\n",
      "Linear\n",
      "Algebra,\n",
      "&\n",
      "Cognitive\n",
      "Neuroscience. \n",
      "●\n",
      "Alpha\n",
      "Kappa\n",
      "Psi\n",
      "-\n",
      "Chair\n",
      "of\n",
      "the\n",
      "philanthropy\n",
      "and\n",
      "professional\n",
      "committees\n",
      "SKILLS\n",
      "Relevant\n",
      "Skills\n",
      ":\n",
      "Machine\n",
      "Learning,\n",
      "Data\n",
      "Analysis,\n",
      "Applied\n",
      "Mathematics,\n",
      "Data\n",
      "Visualization,\n",
      "EEG\n",
      "Data\n",
      "Analysis \n",
      "Related\n",
      "Platforms\n",
      ":\n",
      "Python,\n",
      "Keras,\n",
      "Tensorflow,\n",
      "Pandas,\n",
      "Numpy,\n",
      "Matplotlib,\n",
      "Scikit-Learn,\n",
      "R,\n",
      "SQL,\n",
      "Java,\n",
      "SPSS\n",
      "EXPERIENCE\n",
      "Virtualitics\n",
      "Inc.\n",
      "AI\n",
      "powered\n",
      "data\n",
      "analytics\n",
      "defense\n",
      "contractor.\n",
      "Pasadena,\n",
      "CA \n",
      "AI\n",
      "Data\n",
      "Engineer\n",
      "Intern\n",
      "–\n",
      "Federal\n",
      "Team\n",
      "May\n",
      "2024\n",
      "–\n",
      "August\n",
      "2024 \n",
      "●\n",
      "Implemented\n",
      "transformer-based\n",
      "embeddings\n",
      "to\n",
      "measure\n",
      "text\n",
      "similarity,\n",
      "aiding\n",
      "in\n",
      "tasks\n",
      "like\n",
      "document\n",
      "clustering,\n",
      "data \n",
      "integration,\n",
      "and\n",
      "duplicate\n",
      "detection. \n",
      "●\n",
      "Developed\n",
      "and\n",
      "implemented\n",
      "ETL\n",
      "pipelines,\n",
      "increasing\n",
      "data\n",
      "collection\n",
      "efficiency\n",
      "from\n",
      "diverse\n",
      "sources\n",
      "and\n",
      "over\n",
      "10,000\n",
      "data\n",
      "points \n",
      "for\n",
      "the\n",
      "Department\n",
      "of\n",
      "Defense\n",
      "(DoD).\n",
      "Resulted\n",
      "in\n",
      "a\n",
      "funded\n",
      "project\n",
      "by\n",
      "the\n",
      "DoD. \n",
      "●\n",
      "Integrated\n",
      "transformer\n",
      "models,\n",
      "such\n",
      "as\n",
      "BERT\n",
      "and\n",
      "GPT,\n",
      "into\n",
      "ensemble\n",
      "frameworks\n",
      "for\n",
      "text\n",
      "encoding.\n",
      "California\n",
      "State\n",
      "University,\n",
      "Monterey\n",
      "Bay\n",
      ".\n",
      "Brain-Computer\n",
      "Interface\n",
      "Lab.\n",
      "Seaside,\n",
      "CA \n",
      "Research\n",
      "Assistant\n",
      "February\n",
      "2020\n",
      "–\n",
      "February\n",
      "2024 \n",
      "●\n",
      "Developed\n",
      "computer\n",
      "vision\n",
      "architectures\n",
      "with\n",
      "representation\n",
      "learning\n",
      "and\n",
      "supervised\n",
      "contrastive\n",
      "loss,\n",
      "in\n",
      "a\n",
      "team\n",
      "of\n",
      "five,\n",
      "and\n",
      "applied \n",
      "these\n",
      "architectures\n",
      "in\n",
      "time\n",
      "series\n",
      "analysis\n",
      "of\n",
      "electroencephalogram\n",
      "(EEG)\n",
      "data.\n",
      "Resulted\n",
      "in\n",
      "a\n",
      "publication\n",
      "at\n",
      "AAAI-24\n",
      "conference. \n",
      "●\n",
      "Built\n",
      "ML\n",
      "models\n",
      "with\n",
      "downstream\n",
      "clustering\n",
      "techniques\n",
      "that\n",
      "incorporated\n",
      "EEG\n",
      "data\n",
      "analysis\n",
      "methodologies.\n",
      "Resulted\n",
      "in\n",
      "over\n",
      "70% \n",
      "accuracy\n",
      "of\n",
      "document\n",
      "retrieval. \n",
      "●\n",
      "Played\n",
      "a\n",
      "key\n",
      "role\n",
      "in\n",
      "the\n",
      "development,\n",
      "improvement,\n",
      "and\n",
      "quality\n",
      "control\n",
      "of\n",
      "data\n",
      "sets.\n",
      "SC\n",
      "Planners\n",
      "Land-use\n",
      "development\n",
      "firm.\n",
      "Alhambra,\n",
      "CA \n",
      "Data\n",
      "Engineer\n",
      "Intern\n",
      "August\n",
      "2022\n",
      "–\n",
      "May\n",
      "2023 \n",
      "●\n",
      "Developed\n",
      "and\n",
      "implemented\n",
      "pipelines\n",
      "for\n",
      "extracting\n",
      "data\n",
      "from\n",
      "various\n",
      "government\n",
      "websites,\n",
      "enhancing\n",
      "the\n",
      "efficiency\n",
      "of\n",
      "data \n",
      "ingestion\n",
      "by\n",
      "80%. \n",
      "●\n",
      "Leveraged\n",
      "data\n",
      "analysis\n",
      "skills\n",
      "to\n",
      "contribute\n",
      "to\n",
      "financial\n",
      "analysis,\n",
      "particularly\n",
      "in\n",
      "assessing\n",
      "the\n",
      "impact\n",
      "of\n",
      "urban\n",
      "regulations\n",
      "on \n",
      "investment\n",
      "programs.\n",
      "PROJECTS\n",
      "Fila\n",
      "A\n",
      "3D\n",
      "printing\n",
      "marketplace\n",
      "where\n",
      "users\n",
      "are\n",
      "able\n",
      "to\n",
      "request\n",
      "and\n",
      "fulfill\n",
      "projects\n",
      "(print\n",
      "jobs)\n",
      "across\n",
      "the\n",
      "platform. \n",
      "●\n",
      "Designed\n",
      "and\n",
      "implemented\n",
      "core\n",
      "features\n",
      "for\n",
      "both\n",
      "the\n",
      "publisher\n",
      "and\n",
      "fulfiller\n",
      "workflows,\n",
      "including\n",
      "project\n",
      "creation,\n",
      "browsing, \n",
      "and\n",
      "request\n",
      "management\n",
      "in\n",
      "Java. \n",
      "●\n",
      "Developed\n",
      "RESTful\n",
      "API\n",
      "endpoints\n",
      "using\n",
      "Springboot\n",
      "to\n",
      "handle\n",
      "user\n",
      "authentication,\n",
      "project\n",
      "requests,\n",
      "and\n",
      "profile\n",
      "management. \n",
      "●\n",
      "Integrated\n",
      "Firebase\n",
      "for\n",
      "real-time\n",
      "data\n",
      "management\n",
      "and\n",
      "user\n",
      "authentication,\n",
      "ensuring\n",
      "secure\n",
      "and\n",
      "efficient\n",
      "user\n",
      "sessions.\n",
      "ADDITIONAL\n",
      "●\n",
      "Haidar,\n",
      "M.\n",
      ",\n",
      "&\n",
      "Bruns,\n",
      "G.\n",
      "(2024).\n",
      "Neural\n",
      "Bookmarks:\n",
      "Information\n",
      "Retrieval\n",
      "with\n",
      "Deep\n",
      "Learning\n",
      "and\n",
      "EEG\n",
      "Data.\n",
      "Proceedings\n",
      "of\n",
      "the \n",
      "AAAI\n",
      "Conference\n",
      "on\n",
      "Artificial\n",
      "Intelligence,\n",
      "38(21),\n",
      "22864-22870.\n",
      "https://doi.org/10.1609/aaai.v38i21.30322 \n",
      "●\n",
      "Haidar,\n",
      "M.\n",
      ",\n",
      "Bruns,\n",
      "G.,\n",
      "&\n",
      "Rubino,\n",
      "F.\n",
      "M.\n",
      "(2023).\n",
      "Neural\n",
      "Memory\n",
      "Decoding\n",
      "with\n",
      "EEG\n",
      "Data\n",
      "and\n",
      "Representation\n",
      "Learning.\n",
      "arXiv \n",
      "(Cornell\n",
      "University).\n",
      "https://doi.org/10.48550/arxiv.2307.13181\n",
      "(submitted\n",
      "to\n",
      "ACAIN\n",
      "2024\n",
      ") \n",
      "●\n",
      "Interests:\n",
      "golf,\n",
      "tennis,\n",
      "tinkering\n",
      "with\n",
      "computers\n",
      "\n",
      "Tailored Resume:\n",
      "No Fit\n"
     ]
    }
   ],
   "source": [
    "job_description_image = \"images/job_description_image.jpg\"  # Replace with the actual job description image file path\n",
    "resume_pdf_path = \"resources/Resume.pdf\"  # Replace with the actual resume PDF file path\n",
    "\n",
    "# Step 1: Extract text from the job description image\n",
    "job_description = extract_text_with_paddleocr(job_description_image)\n",
    "print(\"Extracted Job Description:\")\n",
    "print(job_description)\n",
    "\n",
    "# Step 2: Extract text from the resume PDF\n",
    "original_resume_text = extract_text_from_pdf(resume_pdf_path)\n",
    "print(\"\\nExtracted Original Resume Text:\")\n",
    "print(original_resume_text)\n",
    "\n",
    "# Step 3: Generate a tailored resume\n",
    "tailored_resume = generate_matching_resume(job_description, original_resume_text)\n",
    "print(\"\\nTailored Resume:\")\n",
    "print(tailored_resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The model's underperformance in generating tailored resumes could stem from several factors. First, fine-tuning the T5-small model may have been insufficient for generating coherent, professional resumes due to the complexity of resume formatting and content prioritization. The training data may not have provided enough diverse examples of high-quality resumes and their alignment with job descriptions, limiting the model's ability to generalize effectively. Additionally, truncation of input data during tokenization could have caused the model to lose critical context from longer resumes or job descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another contributing factor could be the lack of explicit training for formatting resumes in a professional structure, as T5 is primarily optimized for text-to-text tasks rather than structured document generation. The model also likely struggled to balance creativity with precision, essential for accurately reflecting a candidate's qualifications while adhering to job requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future efforts could include expanding the dataset with more annotated examples of resumes and job descriptions, ensuring a diverse representation of industries and roles. Incorporating additional pre-processing steps, such as segmenting resumes into discrete sections, could provide the model with more structured input. Fine-tuning larger transformer models, like T5-base or T5-large, might improve performance by leveraging their greater capacity to understand and generate complex content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
